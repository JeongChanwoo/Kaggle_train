{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2018)\n",
    "\n",
    "trn = pd.read_csv('/home/jeongchanwoo/workspace/git/study/Kaggle_data/santander-product-recommendation/input/train_ver2.csv')\n",
    "tst = pd.read_csv('/home/jeongchanwoo/workspace/git/study/Kaggle_data/santander-product-recommendation/input/test_ver2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 전처리 ##\n",
    "\n",
    "# 제품 변수\n",
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "# 제품 변수 결측값 0으로 대체\n",
    "trn[prods] = trn[prods].fillna(0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#24개 제품 중 하나도 보유하지 않은 고객 제거\n",
    "no_product = trn[prods].sum(axis=1) ==0\n",
    "trn = trn[~no_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 테스트 데이터 통합 테스트 데이터에 없는 제품 변수 0으로 채움\n",
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([trn, tst], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 변수 list\n",
    "features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp','canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel = -99)\n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([137940.75, '         NA'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['renta'][929602].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87218.1, 35548.74, 122179.11000000002, ..., '  139164.12',\n",
       "       '  100647.45', '   72765.27'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.renta.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수의 특이값, 결측값 -99로 대체하고 정수형 변환\n",
    "df['age'].replace(' NA', -99, inplace = True)\n",
    "df['age']  = df['age'].astype(np.int8)\n",
    "\n",
    "df['antiguedad'].replace('     NA', -99, inplace = True)\n",
    "df['antiguedad']  = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "df['renta'].replace('         NA', -99, inplace = True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta']  = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "df['indrel_1mes'].replace('P', 5, inplace = True)\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes']  = df['indrel_1mes'].astype(float).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용되는 수치형 변수 features에 추가\n",
    "features += ['age' ,'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 변수에서 연도와 월 정보 추출\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x : 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x : 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x : 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x : 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그외 변수의 결측값은 -99로 대체\n",
    "df.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag-1 데이터 생성\n",
    "\n",
    "# 날짜를 숫자로 변환\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")]\n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "\n",
    "# 날짜를 숫자로 변환해 int_date에 저장\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "#데이터 카피하고 , int_date 날짜에 1을 더해 lag를 생성, 변수명에 _prev 추가\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns]\n",
    "df_lag['int_date'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본과 lag데이터를 ncodper와 int_date기준으로 합침\n",
    "df_trn = df.merge(df_lag, on=['ncodpers', 'int_date'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, df_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전 달의 제품 정보가 존재 하지 않을시 0으로 대체\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace = True)\n",
    "\n",
    "df_trn.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lag - 1 변수 추가\n",
    "features +=  [feature + '_prev' for feature in features]\n",
    "features +=  [prod + '_prev' for prod in prods]\n",
    "\n",
    "\n",
    "###\n",
    "### 추가 피쳐 엔지니어링\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind_empleado',\n",
       " 'pais_residencia',\n",
       " 'sexo',\n",
       " 'tiprel_1mes',\n",
       " 'indresi',\n",
       " 'indext',\n",
       " 'conyuemp',\n",
       " 'canal_entrada',\n",
       " 'indfall',\n",
       " 'tipodom',\n",
       " 'nomprov',\n",
       " 'segmento',\n",
       " 'age',\n",
       " 'antiguedad',\n",
       " 'renta',\n",
       " 'ind_nuevo',\n",
       " 'indrel',\n",
       " 'indrel_1mes',\n",
       " 'ind_actividad_cliente',\n",
       " 'fecha_alta_month',\n",
       " 'fecha_alta_year',\n",
       " 'ult_fec_cli_1t_month',\n",
       " 'ult_fec_cli_1t_year',\n",
       " 'ind_empleado_prev',\n",
       " 'pais_residencia_prev',\n",
       " 'sexo_prev',\n",
       " 'tiprel_1mes_prev',\n",
       " 'indresi_prev',\n",
       " 'indext_prev',\n",
       " 'conyuemp_prev',\n",
       " 'canal_entrada_prev',\n",
       " 'indfall_prev',\n",
       " 'tipodom_prev',\n",
       " 'nomprov_prev',\n",
       " 'segmento_prev',\n",
       " 'age_prev',\n",
       " 'antiguedad_prev',\n",
       " 'renta_prev',\n",
       " 'ind_nuevo_prev',\n",
       " 'indrel_prev',\n",
       " 'indrel_1mes_prev',\n",
       " 'ind_actividad_cliente_prev',\n",
       " 'fecha_alta_month_prev',\n",
       " 'fecha_alta_year_prev',\n",
       " 'ult_fec_cli_1t_month_prev',\n",
       " 'ult_fec_cli_1t_year_prev',\n",
       " 'ind_ahor_fin_ult1_prev',\n",
       " 'ind_aval_fin_ult1_prev',\n",
       " 'ind_cco_fin_ult1_prev',\n",
       " 'ind_cder_fin_ult1_prev',\n",
       " 'ind_cno_fin_ult1_prev',\n",
       " 'ind_ctju_fin_ult1_prev',\n",
       " 'ind_ctma_fin_ult1_prev',\n",
       " 'ind_ctop_fin_ult1_prev',\n",
       " 'ind_ctpp_fin_ult1_prev',\n",
       " 'ind_deco_fin_ult1_prev',\n",
       " 'ind_deme_fin_ult1_prev',\n",
       " 'ind_dela_fin_ult1_prev',\n",
       " 'ind_ecue_fin_ult1_prev',\n",
       " 'ind_fond_fin_ult1_prev',\n",
       " 'ind_hip_fin_ult1_prev',\n",
       " 'ind_plan_fin_ult1_prev',\n",
       " 'ind_pres_fin_ult1_prev',\n",
       " 'ind_reca_fin_ult1_prev',\n",
       " 'ind_tjcr_fin_ult1_prev',\n",
       " 'ind_valo_fin_ult1_prev',\n",
       " 'ind_viv_fin_ult1_prev',\n",
       " 'ind_nomina_ult1_prev',\n",
       " 'ind_nom_pens_ult1_prev',\n",
       " 'ind_recibo_ult1_prev']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016-01-28 ~ 2016-04-28데이터를 학습에 사용하고\n",
    "# 검증에 2016-05-28 데이터를 사용한다.\n",
    "\n",
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에서 신규 구매 건수만 추출\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i,prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0 )] # 상품 구매자\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i #상품 숫자(LE)\n",
    "    X.append(prX)\n",
    "    Y.append(prY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 검증 데이터 분리\n",
    "vld_date = '2016-05-28'\n",
    "xy_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "xy_vld = XY[XY['fecha_dato'] == vld_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:20: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:21: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'booster' : 'gbtree',\n",
    "    'max_depth' : 8,\n",
    "    'nthread' : -1,\n",
    "    'num_class' : len(prods),\n",
    "    'objective' : 'multi:softprob',\n",
    "    'silent' : 1,\n",
    "    'eval_metric' : 'mlogloss',\n",
    "    'eta' : 0.1,\n",
    "    'min_child_weight' : 10,\n",
    "    'colsample_bytree' : 0.8,\n",
    "    'colsample_bylevel' : 0.9,\n",
    "    'seed' : 2018,\n",
    "    'max_bin': 16, # GPU \n",
    "    'tree_method': 'gpu_hist', # GPU method (자세한 설명은 문서로!)\n",
    "    'predictor':'gpu_predictor' # train뿐만아니라 predict할때도 gpu쓸건지 결정\n",
    "    \n",
    "}\n",
    "# XGBoost 형태로 훈련, 검증 데이터 변환\n",
    "X_trn = xy_trn.as_matrix(columns=features)\n",
    "Y_trn = xy_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
    "\n",
    "X_vld = xy_vld.as_matrix(columns=features)\n",
    "Y_vld = xy_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.75913\teval-mlogloss:2.784\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:2.53812\teval-mlogloss:2.5674\n",
      "[2]\ttrain-mlogloss:2.37132\teval-mlogloss:2.40377\n",
      "[3]\ttrain-mlogloss:2.21234\teval-mlogloss:2.24439\n",
      "[4]\ttrain-mlogloss:2.08782\teval-mlogloss:2.11911\n",
      "[5]\ttrain-mlogloss:1.98199\teval-mlogloss:2.01291\n",
      "[6]\ttrain-mlogloss:1.89548\teval-mlogloss:1.92643\n",
      "[7]\ttrain-mlogloss:1.82052\teval-mlogloss:1.85058\n",
      "[8]\ttrain-mlogloss:1.75791\teval-mlogloss:1.78776\n",
      "[9]\ttrain-mlogloss:1.70137\teval-mlogloss:1.73079\n",
      "[10]\ttrain-mlogloss:1.65118\teval-mlogloss:1.68072\n",
      "[11]\ttrain-mlogloss:1.60467\teval-mlogloss:1.63358\n",
      "[12]\ttrain-mlogloss:1.56373\teval-mlogloss:1.59332\n",
      "[13]\ttrain-mlogloss:1.52618\teval-mlogloss:1.55517\n",
      "[14]\ttrain-mlogloss:1.49251\teval-mlogloss:1.52156\n",
      "[15]\ttrain-mlogloss:1.46185\teval-mlogloss:1.49053\n",
      "[16]\ttrain-mlogloss:1.43552\teval-mlogloss:1.46422\n",
      "[17]\ttrain-mlogloss:1.41193\teval-mlogloss:1.4408\n",
      "[18]\ttrain-mlogloss:1.3889\teval-mlogloss:1.41757\n",
      "[19]\ttrain-mlogloss:1.36757\teval-mlogloss:1.39587\n",
      "[20]\ttrain-mlogloss:1.34944\teval-mlogloss:1.37818\n",
      "[21]\ttrain-mlogloss:1.33192\teval-mlogloss:1.36049\n",
      "[22]\ttrain-mlogloss:1.31532\teval-mlogloss:1.34375\n",
      "[23]\ttrain-mlogloss:1.29997\teval-mlogloss:1.32855\n",
      "[24]\ttrain-mlogloss:1.28617\teval-mlogloss:1.31494\n",
      "[25]\ttrain-mlogloss:1.27292\teval-mlogloss:1.30147\n",
      "[26]\ttrain-mlogloss:1.26097\teval-mlogloss:1.28985\n",
      "[27]\ttrain-mlogloss:1.25032\teval-mlogloss:1.27928\n",
      "[28]\ttrain-mlogloss:1.23967\teval-mlogloss:1.26863\n",
      "[29]\ttrain-mlogloss:1.22963\teval-mlogloss:1.25877\n",
      "[30]\ttrain-mlogloss:1.22033\teval-mlogloss:1.24953\n",
      "[31]\ttrain-mlogloss:1.21155\teval-mlogloss:1.24077\n",
      "[32]\ttrain-mlogloss:1.20339\teval-mlogloss:1.23306\n",
      "[33]\ttrain-mlogloss:1.19569\teval-mlogloss:1.22569\n",
      "[34]\ttrain-mlogloss:1.18869\teval-mlogloss:1.21891\n",
      "[35]\ttrain-mlogloss:1.18202\teval-mlogloss:1.21239\n",
      "[36]\ttrain-mlogloss:1.17613\teval-mlogloss:1.20703\n",
      "[37]\ttrain-mlogloss:1.17028\teval-mlogloss:1.20161\n",
      "[38]\ttrain-mlogloss:1.1649\teval-mlogloss:1.19682\n",
      "[39]\ttrain-mlogloss:1.1597\teval-mlogloss:1.19191\n",
      "[40]\ttrain-mlogloss:1.15475\teval-mlogloss:1.18754\n",
      "[41]\ttrain-mlogloss:1.14995\teval-mlogloss:1.18299\n",
      "[42]\ttrain-mlogloss:1.14543\teval-mlogloss:1.17879\n",
      "[43]\ttrain-mlogloss:1.14118\teval-mlogloss:1.17477\n",
      "[44]\ttrain-mlogloss:1.1372\teval-mlogloss:1.17139\n",
      "[45]\ttrain-mlogloss:1.13339\teval-mlogloss:1.16821\n",
      "[46]\ttrain-mlogloss:1.1299\teval-mlogloss:1.16493\n",
      "[47]\ttrain-mlogloss:1.1264\teval-mlogloss:1.1618\n",
      "[48]\ttrain-mlogloss:1.12326\teval-mlogloss:1.15884\n",
      "[49]\ttrain-mlogloss:1.1203\teval-mlogloss:1.15616\n",
      "[50]\ttrain-mlogloss:1.11744\teval-mlogloss:1.15354\n",
      "[51]\ttrain-mlogloss:1.11472\teval-mlogloss:1.15119\n",
      "[52]\ttrain-mlogloss:1.11224\teval-mlogloss:1.14925\n",
      "[53]\ttrain-mlogloss:1.10969\teval-mlogloss:1.14723\n",
      "[54]\ttrain-mlogloss:1.10726\teval-mlogloss:1.14501\n",
      "[55]\ttrain-mlogloss:1.10499\teval-mlogloss:1.143\n",
      "[56]\ttrain-mlogloss:1.10278\teval-mlogloss:1.14117\n",
      "[57]\ttrain-mlogloss:1.10072\teval-mlogloss:1.13938\n",
      "[58]\ttrain-mlogloss:1.09887\teval-mlogloss:1.13795\n",
      "[59]\ttrain-mlogloss:1.09698\teval-mlogloss:1.13631\n",
      "[60]\ttrain-mlogloss:1.09513\teval-mlogloss:1.13482\n",
      "[61]\ttrain-mlogloss:1.09339\teval-mlogloss:1.1334\n",
      "[62]\ttrain-mlogloss:1.09165\teval-mlogloss:1.13202\n",
      "[63]\ttrain-mlogloss:1.09001\teval-mlogloss:1.13074\n",
      "[64]\ttrain-mlogloss:1.0885\teval-mlogloss:1.12951\n",
      "[65]\ttrain-mlogloss:1.08689\teval-mlogloss:1.1283\n",
      "[66]\ttrain-mlogloss:1.08548\teval-mlogloss:1.12728\n",
      "[67]\ttrain-mlogloss:1.08415\teval-mlogloss:1.12627\n",
      "[68]\ttrain-mlogloss:1.08277\teval-mlogloss:1.1252\n",
      "[69]\ttrain-mlogloss:1.08146\teval-mlogloss:1.12422\n",
      "[70]\ttrain-mlogloss:1.08025\teval-mlogloss:1.1233\n",
      "[71]\ttrain-mlogloss:1.07897\teval-mlogloss:1.12243\n",
      "[72]\ttrain-mlogloss:1.07771\teval-mlogloss:1.12157\n",
      "[73]\ttrain-mlogloss:1.07648\teval-mlogloss:1.12076\n",
      "[74]\ttrain-mlogloss:1.07535\teval-mlogloss:1.11999\n",
      "[75]\ttrain-mlogloss:1.07424\teval-mlogloss:1.11926\n",
      "[76]\ttrain-mlogloss:1.07314\teval-mlogloss:1.11865\n",
      "[77]\ttrain-mlogloss:1.07213\teval-mlogloss:1.11801\n",
      "[78]\ttrain-mlogloss:1.07113\teval-mlogloss:1.11736\n",
      "[79]\ttrain-mlogloss:1.0702\teval-mlogloss:1.11683\n",
      "[80]\ttrain-mlogloss:1.06927\teval-mlogloss:1.11623\n",
      "[81]\ttrain-mlogloss:1.0684\teval-mlogloss:1.11574\n",
      "[82]\ttrain-mlogloss:1.0674\teval-mlogloss:1.11521\n",
      "[83]\ttrain-mlogloss:1.06651\teval-mlogloss:1.11475\n",
      "[84]\ttrain-mlogloss:1.06569\teval-mlogloss:1.11429\n",
      "[85]\ttrain-mlogloss:1.06479\teval-mlogloss:1.11388\n",
      "[86]\ttrain-mlogloss:1.06408\teval-mlogloss:1.11348\n",
      "[87]\ttrain-mlogloss:1.06328\teval-mlogloss:1.11299\n",
      "[88]\ttrain-mlogloss:1.06258\teval-mlogloss:1.11255\n",
      "[89]\ttrain-mlogloss:1.06189\teval-mlogloss:1.11218\n",
      "[90]\ttrain-mlogloss:1.06123\teval-mlogloss:1.11184\n",
      "[91]\ttrain-mlogloss:1.06038\teval-mlogloss:1.11149\n",
      "[92]\ttrain-mlogloss:1.05963\teval-mlogloss:1.11124\n",
      "[93]\ttrain-mlogloss:1.05902\teval-mlogloss:1.11095\n",
      "[94]\ttrain-mlogloss:1.05821\teval-mlogloss:1.11059\n",
      "[95]\ttrain-mlogloss:1.05747\teval-mlogloss:1.11019\n",
      "[96]\ttrain-mlogloss:1.05672\teval-mlogloss:1.10994\n",
      "[97]\ttrain-mlogloss:1.05603\teval-mlogloss:1.10967\n",
      "[98]\ttrain-mlogloss:1.05538\teval-mlogloss:1.10949\n",
      "[99]\ttrain-mlogloss:1.05473\teval-mlogloss:1.10925\n",
      "[100]\ttrain-mlogloss:1.0541\teval-mlogloss:1.10898\n",
      "[101]\ttrain-mlogloss:1.05339\teval-mlogloss:1.10875\n",
      "[102]\ttrain-mlogloss:1.05267\teval-mlogloss:1.10853\n",
      "[103]\ttrain-mlogloss:1.05199\teval-mlogloss:1.10832\n",
      "[104]\ttrain-mlogloss:1.05138\teval-mlogloss:1.10808\n",
      "[105]\ttrain-mlogloss:1.05083\teval-mlogloss:1.10789\n",
      "[106]\ttrain-mlogloss:1.05027\teval-mlogloss:1.10777\n",
      "[107]\ttrain-mlogloss:1.04961\teval-mlogloss:1.10761\n",
      "[108]\ttrain-mlogloss:1.04906\teval-mlogloss:1.10745\n",
      "[109]\ttrain-mlogloss:1.04848\teval-mlogloss:1.10733\n",
      "[110]\ttrain-mlogloss:1.04781\teval-mlogloss:1.10714\n",
      "[111]\ttrain-mlogloss:1.04716\teval-mlogloss:1.10718\n",
      "[112]\ttrain-mlogloss:1.04662\teval-mlogloss:1.10703\n",
      "[113]\ttrain-mlogloss:1.04594\teval-mlogloss:1.10693\n",
      "[114]\ttrain-mlogloss:1.04541\teval-mlogloss:1.10675\n",
      "[115]\ttrain-mlogloss:1.0448\teval-mlogloss:1.10659\n",
      "[116]\ttrain-mlogloss:1.04423\teval-mlogloss:1.10648\n",
      "[117]\ttrain-mlogloss:1.04363\teval-mlogloss:1.10635\n",
      "[118]\ttrain-mlogloss:1.04299\teval-mlogloss:1.10626\n",
      "[119]\ttrain-mlogloss:1.04232\teval-mlogloss:1.10617\n",
      "[120]\ttrain-mlogloss:1.04182\teval-mlogloss:1.10609\n",
      "[121]\ttrain-mlogloss:1.04125\teval-mlogloss:1.10598\n",
      "[122]\ttrain-mlogloss:1.04062\teval-mlogloss:1.10588\n",
      "[123]\ttrain-mlogloss:1.04002\teval-mlogloss:1.10575\n",
      "[124]\ttrain-mlogloss:1.03947\teval-mlogloss:1.10569\n",
      "[125]\ttrain-mlogloss:1.0388\teval-mlogloss:1.10563\n",
      "[126]\ttrain-mlogloss:1.03823\teval-mlogloss:1.10556\n",
      "[127]\ttrain-mlogloss:1.03766\teval-mlogloss:1.10546\n",
      "[128]\ttrain-mlogloss:1.03706\teval-mlogloss:1.10539\n",
      "[129]\ttrain-mlogloss:1.03639\teval-mlogloss:1.10533\n",
      "[130]\ttrain-mlogloss:1.03579\teval-mlogloss:1.10527\n",
      "[131]\ttrain-mlogloss:1.03516\teval-mlogloss:1.10523\n",
      "[132]\ttrain-mlogloss:1.03454\teval-mlogloss:1.10514\n",
      "[133]\ttrain-mlogloss:1.03399\teval-mlogloss:1.10504\n",
      "[134]\ttrain-mlogloss:1.03339\teval-mlogloss:1.10499\n",
      "[135]\ttrain-mlogloss:1.03294\teval-mlogloss:1.10494\n",
      "[136]\ttrain-mlogloss:1.03231\teval-mlogloss:1.10486\n",
      "[137]\ttrain-mlogloss:1.03181\teval-mlogloss:1.10481\n",
      "[138]\ttrain-mlogloss:1.03128\teval-mlogloss:1.10474\n",
      "[139]\ttrain-mlogloss:1.03082\teval-mlogloss:1.10471\n",
      "[140]\ttrain-mlogloss:1.03037\teval-mlogloss:1.10464\n",
      "[141]\ttrain-mlogloss:1.0297\teval-mlogloss:1.10459\n",
      "[142]\ttrain-mlogloss:1.02913\teval-mlogloss:1.10455\n",
      "[143]\ttrain-mlogloss:1.02849\teval-mlogloss:1.10443\n",
      "[144]\ttrain-mlogloss:1.02788\teval-mlogloss:1.10437\n",
      "[145]\ttrain-mlogloss:1.02721\teval-mlogloss:1.10428\n",
      "[146]\ttrain-mlogloss:1.02649\teval-mlogloss:1.10417\n",
      "[147]\ttrain-mlogloss:1.0257\teval-mlogloss:1.10408\n",
      "[148]\ttrain-mlogloss:1.02514\teval-mlogloss:1.10397\n",
      "[149]\ttrain-mlogloss:1.02458\teval-mlogloss:1.10392\n",
      "[150]\ttrain-mlogloss:1.02407\teval-mlogloss:1.10391\n",
      "[151]\ttrain-mlogloss:1.02349\teval-mlogloss:1.10385\n",
      "[152]\ttrain-mlogloss:1.02307\teval-mlogloss:1.1038\n",
      "[153]\ttrain-mlogloss:1.02242\teval-mlogloss:1.10386\n",
      "[154]\ttrain-mlogloss:1.02184\teval-mlogloss:1.1039\n",
      "[155]\ttrain-mlogloss:1.02129\teval-mlogloss:1.10391\n",
      "[156]\ttrain-mlogloss:1.02081\teval-mlogloss:1.10392\n",
      "[157]\ttrain-mlogloss:1.02021\teval-mlogloss:1.10391\n",
      "[158]\ttrain-mlogloss:1.01961\teval-mlogloss:1.10392\n",
      "[159]\ttrain-mlogloss:1.01906\teval-mlogloss:1.10391\n",
      "[160]\ttrain-mlogloss:1.01853\teval-mlogloss:1.10387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttrain-mlogloss:1.01798\teval-mlogloss:1.10385\n",
      "[162]\ttrain-mlogloss:1.01726\teval-mlogloss:1.10384\n",
      "[163]\ttrain-mlogloss:1.01673\teval-mlogloss:1.10384\n",
      "[164]\ttrain-mlogloss:1.01627\teval-mlogloss:1.10381\n",
      "[165]\ttrain-mlogloss:1.01567\teval-mlogloss:1.10375\n",
      "[166]\ttrain-mlogloss:1.01508\teval-mlogloss:1.10381\n",
      "[167]\ttrain-mlogloss:1.01456\teval-mlogloss:1.10378\n",
      "[168]\ttrain-mlogloss:1.01397\teval-mlogloss:1.10375\n",
      "[169]\ttrain-mlogloss:1.01342\teval-mlogloss:1.10371\n",
      "[170]\ttrain-mlogloss:1.01292\teval-mlogloss:1.10367\n",
      "[171]\ttrain-mlogloss:1.0125\teval-mlogloss:1.10367\n",
      "[172]\ttrain-mlogloss:1.01197\teval-mlogloss:1.10369\n",
      "[173]\ttrain-mlogloss:1.01141\teval-mlogloss:1.1037\n",
      "[174]\ttrain-mlogloss:1.01084\teval-mlogloss:1.10374\n",
      "[175]\ttrain-mlogloss:1.01021\teval-mlogloss:1.10372\n",
      "[176]\ttrain-mlogloss:1.00946\teval-mlogloss:1.1037\n",
      "[177]\ttrain-mlogloss:1.009\teval-mlogloss:1.10367\n",
      "[178]\ttrain-mlogloss:1.00847\teval-mlogloss:1.10361\n",
      "[179]\ttrain-mlogloss:1.00809\teval-mlogloss:1.1036\n",
      "[180]\ttrain-mlogloss:1.00746\teval-mlogloss:1.1036\n",
      "[181]\ttrain-mlogloss:1.00693\teval-mlogloss:1.10353\n",
      "[182]\ttrain-mlogloss:1.00636\teval-mlogloss:1.1035\n",
      "[183]\ttrain-mlogloss:1.00581\teval-mlogloss:1.10354\n",
      "[184]\ttrain-mlogloss:1.00533\teval-mlogloss:1.1035\n",
      "[185]\ttrain-mlogloss:1.00484\teval-mlogloss:1.10355\n",
      "[186]\ttrain-mlogloss:1.00434\teval-mlogloss:1.10355\n",
      "[187]\ttrain-mlogloss:1.00366\teval-mlogloss:1.10351\n",
      "[188]\ttrain-mlogloss:1.0031\teval-mlogloss:1.10352\n",
      "[189]\ttrain-mlogloss:1.00255\teval-mlogloss:1.1035\n",
      "[190]\ttrain-mlogloss:1.00196\teval-mlogloss:1.10343\n",
      "[191]\ttrain-mlogloss:1.00144\teval-mlogloss:1.1034\n",
      "[192]\ttrain-mlogloss:1.00076\teval-mlogloss:1.10337\n",
      "[193]\ttrain-mlogloss:1.00017\teval-mlogloss:1.10337\n",
      "[194]\ttrain-mlogloss:0.999626\teval-mlogloss:1.10335\n",
      "[195]\ttrain-mlogloss:0.999189\teval-mlogloss:1.10337\n",
      "[196]\ttrain-mlogloss:0.998773\teval-mlogloss:1.10336\n",
      "[197]\ttrain-mlogloss:0.998334\teval-mlogloss:1.10334\n",
      "[198]\ttrain-mlogloss:0.997971\teval-mlogloss:1.10337\n",
      "[199]\ttrain-mlogloss:0.997546\teval-mlogloss:1.10335\n",
      "[200]\ttrain-mlogloss:0.99707\teval-mlogloss:1.10328\n",
      "[201]\ttrain-mlogloss:0.996596\teval-mlogloss:1.10325\n",
      "[202]\ttrain-mlogloss:0.996222\teval-mlogloss:1.10322\n",
      "[203]\ttrain-mlogloss:0.995627\teval-mlogloss:1.10319\n",
      "[204]\ttrain-mlogloss:0.99521\teval-mlogloss:1.10321\n",
      "[205]\ttrain-mlogloss:0.994852\teval-mlogloss:1.10326\n",
      "[206]\ttrain-mlogloss:0.994498\teval-mlogloss:1.10323\n",
      "[207]\ttrain-mlogloss:0.994125\teval-mlogloss:1.10327\n",
      "[208]\ttrain-mlogloss:0.993747\teval-mlogloss:1.10345\n",
      "[209]\ttrain-mlogloss:0.993136\teval-mlogloss:1.10345\n",
      "[210]\ttrain-mlogloss:0.992645\teval-mlogloss:1.10344\n",
      "[211]\ttrain-mlogloss:0.992201\teval-mlogloss:1.10345\n",
      "[212]\ttrain-mlogloss:0.991814\teval-mlogloss:1.10344\n",
      "[213]\ttrain-mlogloss:0.991219\teval-mlogloss:1.10337\n",
      "[214]\ttrain-mlogloss:0.99068\teval-mlogloss:1.10336\n",
      "[215]\ttrain-mlogloss:0.990152\teval-mlogloss:1.1034\n",
      "[216]\ttrain-mlogloss:0.989665\teval-mlogloss:1.10344\n",
      "[217]\ttrain-mlogloss:0.989135\teval-mlogloss:1.10346\n",
      "[218]\ttrain-mlogloss:0.988712\teval-mlogloss:1.10348\n",
      "[219]\ttrain-mlogloss:0.988282\teval-mlogloss:1.10347\n",
      "[220]\ttrain-mlogloss:0.987704\teval-mlogloss:1.10344\n",
      "[221]\ttrain-mlogloss:0.987268\teval-mlogloss:1.10346\n",
      "[222]\ttrain-mlogloss:0.986686\teval-mlogloss:1.10342\n",
      "[223]\ttrain-mlogloss:0.986205\teval-mlogloss:1.10343\n",
      "Stopping. Best iteration:\n",
      "[203]\ttrain-mlogloss:0.995627\teval-mlogloss:1.10319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"./model/xgb.baseline.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#고객 식별 번호 추출\n",
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld.as_matrix(columns = ['ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터에서 신규 구매를 구함\n",
    "for prod in prods:\n",
    "    prev = prod +'_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]\n",
    "    \n",
    "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객별 신규 구매 정답값을 add_vld_list에 저장, 총 count를 count_vld에 저장\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapk import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04266379915553903\n"
     ]
    }
   ],
   "source": [
    "print(mapk(add_vld_list, add_vld_list, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터에 대한 예측 값\n",
    "X_vld = vld.as_matrix(columns=features)\n",
    "Y_vld = vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names= features)\n",
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 저번 달 보유한 제품은 신규구매 불가이기에 확률값에서 미리 1을 빼줌\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증 데이터 예측 상위 7개\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y,p, ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a : a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p, ip in y_prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036266311174317035\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터에서 MAP@7 점수 구함\n",
    "print(mapk(add_vld_list,result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 캐글 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 모델을 전체 훈련 데이터로 재학습\n",
    "X_all  = XY.as_matrix(columns=features)\n",
    "Y_all = XY.as_matrix(columns=['y'])\n",
    "dall  = xgb.DMatrix(X_all, label=Y_all, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_list = [(dall, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 개수를 늘어난 데이터 양만큼 비례해서 증가\n",
    "best_ntree_limit = int(best_ntree_limit * (len(xy_trn) + len(xy_vld))/ len(xy_trn) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.76102\n",
      "[1]\ttrain-mlogloss:2.53979\n",
      "[2]\ttrain-mlogloss:2.34682\n",
      "[3]\ttrain-mlogloss:2.19149\n",
      "[4]\ttrain-mlogloss:2.07457\n",
      "[5]\ttrain-mlogloss:1.98141\n",
      "[6]\ttrain-mlogloss:1.89429\n",
      "[7]\ttrain-mlogloss:1.81817\n",
      "[8]\ttrain-mlogloss:1.75744\n",
      "[9]\ttrain-mlogloss:1.69884\n",
      "[10]\ttrain-mlogloss:1.64685\n",
      "[11]\ttrain-mlogloss:1.60126\n",
      "[12]\ttrain-mlogloss:1.56056\n",
      "[13]\ttrain-mlogloss:1.52531\n",
      "[14]\ttrain-mlogloss:1.49293\n",
      "[15]\ttrain-mlogloss:1.46454\n",
      "[16]\ttrain-mlogloss:1.43677\n",
      "[17]\ttrain-mlogloss:1.41226\n",
      "[18]\ttrain-mlogloss:1.39071\n",
      "[19]\ttrain-mlogloss:1.36975\n",
      "[20]\ttrain-mlogloss:1.35069\n",
      "[21]\ttrain-mlogloss:1.33344\n",
      "[22]\ttrain-mlogloss:1.31765\n",
      "[23]\ttrain-mlogloss:1.30279\n",
      "[24]\ttrain-mlogloss:1.28822\n",
      "[25]\ttrain-mlogloss:1.27598\n",
      "[26]\ttrain-mlogloss:1.26338\n",
      "[27]\ttrain-mlogloss:1.25253\n",
      "[28]\ttrain-mlogloss:1.24163\n",
      "[29]\ttrain-mlogloss:1.23178\n",
      "[30]\ttrain-mlogloss:1.22251\n",
      "[31]\ttrain-mlogloss:1.21429\n",
      "[32]\ttrain-mlogloss:1.20645\n",
      "[33]\ttrain-mlogloss:1.19877\n",
      "[34]\ttrain-mlogloss:1.19138\n",
      "[35]\ttrain-mlogloss:1.18447\n",
      "[36]\ttrain-mlogloss:1.17814\n",
      "[37]\ttrain-mlogloss:1.17209\n",
      "[38]\ttrain-mlogloss:1.16641\n",
      "[39]\ttrain-mlogloss:1.1609\n",
      "[40]\ttrain-mlogloss:1.1561\n",
      "[41]\ttrain-mlogloss:1.15151\n",
      "[42]\ttrain-mlogloss:1.14694\n",
      "[43]\ttrain-mlogloss:1.14257\n",
      "[44]\ttrain-mlogloss:1.1385\n",
      "[45]\ttrain-mlogloss:1.13497\n",
      "[46]\ttrain-mlogloss:1.1316\n",
      "[47]\ttrain-mlogloss:1.12827\n",
      "[48]\ttrain-mlogloss:1.12488\n",
      "[49]\ttrain-mlogloss:1.1218\n",
      "[50]\ttrain-mlogloss:1.11878\n",
      "[51]\ttrain-mlogloss:1.11603\n",
      "[52]\ttrain-mlogloss:1.11327\n",
      "[53]\ttrain-mlogloss:1.11085\n",
      "[54]\ttrain-mlogloss:1.10844\n",
      "[55]\ttrain-mlogloss:1.10615\n",
      "[56]\ttrain-mlogloss:1.10391\n",
      "[57]\ttrain-mlogloss:1.10185\n",
      "[58]\ttrain-mlogloss:1.09986\n",
      "[59]\ttrain-mlogloss:1.09799\n",
      "[60]\ttrain-mlogloss:1.09601\n",
      "[61]\ttrain-mlogloss:1.09414\n",
      "[62]\ttrain-mlogloss:1.09242\n",
      "[63]\ttrain-mlogloss:1.09079\n",
      "[64]\ttrain-mlogloss:1.08921\n",
      "[65]\ttrain-mlogloss:1.08774\n",
      "[66]\ttrain-mlogloss:1.08625\n",
      "[67]\ttrain-mlogloss:1.08491\n",
      "[68]\ttrain-mlogloss:1.08363\n",
      "[69]\ttrain-mlogloss:1.08241\n",
      "[70]\ttrain-mlogloss:1.08127\n",
      "[71]\ttrain-mlogloss:1.08008\n",
      "[72]\ttrain-mlogloss:1.07894\n",
      "[73]\ttrain-mlogloss:1.07796\n",
      "[74]\ttrain-mlogloss:1.07682\n",
      "[75]\ttrain-mlogloss:1.07576\n",
      "[76]\ttrain-mlogloss:1.07471\n",
      "[77]\ttrain-mlogloss:1.07372\n",
      "[78]\ttrain-mlogloss:1.07277\n",
      "[79]\ttrain-mlogloss:1.07188\n",
      "[80]\ttrain-mlogloss:1.07096\n",
      "[81]\ttrain-mlogloss:1.07004\n",
      "[82]\ttrain-mlogloss:1.06917\n",
      "[83]\ttrain-mlogloss:1.06834\n",
      "[84]\ttrain-mlogloss:1.0676\n",
      "[85]\ttrain-mlogloss:1.06687\n",
      "[86]\ttrain-mlogloss:1.06603\n",
      "[87]\ttrain-mlogloss:1.0652\n",
      "[88]\ttrain-mlogloss:1.06432\n",
      "[89]\ttrain-mlogloss:1.06361\n",
      "[90]\ttrain-mlogloss:1.06288\n",
      "[91]\ttrain-mlogloss:1.06208\n",
      "[92]\ttrain-mlogloss:1.06141\n",
      "[93]\ttrain-mlogloss:1.06078\n",
      "[94]\ttrain-mlogloss:1.06025\n",
      "[95]\ttrain-mlogloss:1.0596\n",
      "[96]\ttrain-mlogloss:1.05902\n",
      "[97]\ttrain-mlogloss:1.05828\n",
      "[98]\ttrain-mlogloss:1.05753\n",
      "[99]\ttrain-mlogloss:1.05694\n",
      "[100]\ttrain-mlogloss:1.05643\n",
      "[101]\ttrain-mlogloss:1.0559\n",
      "[102]\ttrain-mlogloss:1.05533\n",
      "[103]\ttrain-mlogloss:1.05469\n",
      "[104]\ttrain-mlogloss:1.05401\n",
      "[105]\ttrain-mlogloss:1.05348\n",
      "[106]\ttrain-mlogloss:1.05295\n",
      "[107]\ttrain-mlogloss:1.05241\n",
      "[108]\ttrain-mlogloss:1.05185\n",
      "[109]\ttrain-mlogloss:1.05129\n",
      "[110]\ttrain-mlogloss:1.05081\n",
      "[111]\ttrain-mlogloss:1.05032\n",
      "[112]\ttrain-mlogloss:1.0498\n",
      "[113]\ttrain-mlogloss:1.04931\n",
      "[114]\ttrain-mlogloss:1.04882\n",
      "[115]\ttrain-mlogloss:1.04834\n",
      "[116]\ttrain-mlogloss:1.04783\n",
      "[117]\ttrain-mlogloss:1.04716\n",
      "[118]\ttrain-mlogloss:1.04677\n",
      "[119]\ttrain-mlogloss:1.04629\n",
      "[120]\ttrain-mlogloss:1.04579\n",
      "[121]\ttrain-mlogloss:1.0453\n",
      "[122]\ttrain-mlogloss:1.04479\n",
      "[123]\ttrain-mlogloss:1.04428\n",
      "[124]\ttrain-mlogloss:1.04374\n",
      "[125]\ttrain-mlogloss:1.04323\n",
      "[126]\ttrain-mlogloss:1.04254\n",
      "[127]\ttrain-mlogloss:1.04197\n",
      "[128]\ttrain-mlogloss:1.04147\n",
      "[129]\ttrain-mlogloss:1.04091\n",
      "[130]\ttrain-mlogloss:1.04045\n",
      "[131]\ttrain-mlogloss:1.03984\n",
      "[132]\ttrain-mlogloss:1.03923\n",
      "[133]\ttrain-mlogloss:1.0389\n",
      "[134]\ttrain-mlogloss:1.03838\n",
      "[135]\ttrain-mlogloss:1.03796\n",
      "[136]\ttrain-mlogloss:1.03748\n",
      "[137]\ttrain-mlogloss:1.03704\n",
      "[138]\ttrain-mlogloss:1.03657\n",
      "[139]\ttrain-mlogloss:1.03597\n",
      "[140]\ttrain-mlogloss:1.03549\n",
      "[141]\ttrain-mlogloss:1.03497\n",
      "[142]\ttrain-mlogloss:1.03439\n",
      "[143]\ttrain-mlogloss:1.03395\n",
      "[144]\ttrain-mlogloss:1.03345\n",
      "[145]\ttrain-mlogloss:1.03281\n",
      "[146]\ttrain-mlogloss:1.03238\n",
      "[147]\ttrain-mlogloss:1.03185\n",
      "[148]\ttrain-mlogloss:1.03137\n",
      "[149]\ttrain-mlogloss:1.03079\n",
      "[150]\ttrain-mlogloss:1.03028\n",
      "[151]\ttrain-mlogloss:1.02978\n",
      "[152]\ttrain-mlogloss:1.02927\n",
      "[153]\ttrain-mlogloss:1.02886\n",
      "[154]\ttrain-mlogloss:1.02841\n",
      "[155]\ttrain-mlogloss:1.02782\n",
      "[156]\ttrain-mlogloss:1.0273\n",
      "[157]\ttrain-mlogloss:1.0269\n",
      "[158]\ttrain-mlogloss:1.02626\n",
      "[159]\ttrain-mlogloss:1.02585\n",
      "[160]\ttrain-mlogloss:1.02534\n",
      "[161]\ttrain-mlogloss:1.02498\n",
      "[162]\ttrain-mlogloss:1.02446\n",
      "[163]\ttrain-mlogloss:1.02397\n",
      "[164]\ttrain-mlogloss:1.02356\n",
      "[165]\ttrain-mlogloss:1.02319\n",
      "[166]\ttrain-mlogloss:1.02271\n",
      "[167]\ttrain-mlogloss:1.02212\n",
      "[168]\ttrain-mlogloss:1.0218\n",
      "[169]\ttrain-mlogloss:1.02141\n",
      "[170]\ttrain-mlogloss:1.02088\n",
      "[171]\ttrain-mlogloss:1.0204\n",
      "[172]\ttrain-mlogloss:1.01993\n",
      "[173]\ttrain-mlogloss:1.01943\n",
      "[174]\ttrain-mlogloss:1.01892\n",
      "[175]\ttrain-mlogloss:1.01828\n",
      "[176]\ttrain-mlogloss:1.01773\n",
      "[177]\ttrain-mlogloss:1.01732\n",
      "[178]\ttrain-mlogloss:1.01689\n",
      "[179]\ttrain-mlogloss:1.01645\n",
      "[180]\ttrain-mlogloss:1.01598\n",
      "[181]\ttrain-mlogloss:1.01538\n",
      "[182]\ttrain-mlogloss:1.0148\n",
      "[183]\ttrain-mlogloss:1.01439\n",
      "[184]\ttrain-mlogloss:1.01388\n",
      "[185]\ttrain-mlogloss:1.01327\n",
      "[186]\ttrain-mlogloss:1.0127\n",
      "[187]\ttrain-mlogloss:1.01231\n",
      "[188]\ttrain-mlogloss:1.01184\n",
      "[189]\ttrain-mlogloss:1.01151\n",
      "[190]\ttrain-mlogloss:1.01104\n",
      "[191]\ttrain-mlogloss:1.0105\n",
      "[192]\ttrain-mlogloss:1.00996\n",
      "[193]\ttrain-mlogloss:1.0095\n",
      "[194]\ttrain-mlogloss:1.00913\n",
      "[195]\ttrain-mlogloss:1.00871\n",
      "[196]\ttrain-mlogloss:1.00821\n",
      "[197]\ttrain-mlogloss:1.00783\n",
      "[198]\ttrain-mlogloss:1.00739\n",
      "[199]\ttrain-mlogloss:1.00694\n",
      "[200]\ttrain-mlogloss:1.00647\n",
      "[201]\ttrain-mlogloss:1.00605\n",
      "[202]\ttrain-mlogloss:1.00562\n",
      "[203]\ttrain-mlogloss:1.00515\n",
      "[204]\ttrain-mlogloss:1.00455\n",
      "[205]\ttrain-mlogloss:1.00407\n",
      "[206]\ttrain-mlogloss:1.00357\n",
      "[207]\ttrain-mlogloss:1.00315\n",
      "[208]\ttrain-mlogloss:1.00262\n",
      "[209]\ttrain-mlogloss:1.00221\n",
      "[210]\ttrain-mlogloss:1.00175\n",
      "[211]\ttrain-mlogloss:1.00133\n",
      "[212]\ttrain-mlogloss:1.00082\n",
      "[213]\ttrain-mlogloss:1.00042\n",
      "[214]\ttrain-mlogloss:1.00007\n",
      "[215]\ttrain-mlogloss:0.999736\n",
      "[216]\ttrain-mlogloss:0.999388\n",
      "[217]\ttrain-mlogloss:0.998897\n",
      "[218]\ttrain-mlogloss:0.998343\n",
      "[219]\ttrain-mlogloss:0.998023\n",
      "[220]\ttrain-mlogloss:0.997644\n",
      "[221]\ttrain-mlogloss:0.997284\n",
      "[222]\ttrain-mlogloss:0.996866\n",
      "[223]\ttrain-mlogloss:0.996429\n",
      "[224]\ttrain-mlogloss:0.996004\n",
      "[225]\ttrain-mlogloss:0.995504\n",
      "[226]\ttrain-mlogloss:0.995055\n",
      "[227]\ttrain-mlogloss:0.994698\n",
      "[228]\ttrain-mlogloss:0.994258\n",
      "[229]\ttrain-mlogloss:0.993885\n",
      "[230]\ttrain-mlogloss:0.993415\n",
      "[231]\ttrain-mlogloss:0.993041\n",
      "[232]\ttrain-mlogloss:0.992687\n",
      "[233]\ttrain-mlogloss:0.992352\n",
      "[234]\ttrain-mlogloss:0.991899\n",
      "[235]\ttrain-mlogloss:0.991491\n",
      "[236]\ttrain-mlogloss:0.991158\n",
      "[237]\ttrain-mlogloss:0.990788\n",
      "[238]\ttrain-mlogloss:0.990474\n",
      "[239]\ttrain-mlogloss:0.990092\n",
      "[240]\ttrain-mlogloss:0.989756\n",
      "[241]\ttrain-mlogloss:0.989288\n",
      "[242]\ttrain-mlogloss:0.988928\n",
      "[243]\ttrain-mlogloss:0.988627\n",
      "[244]\ttrain-mlogloss:0.98821\n",
      "[245]\ttrain-mlogloss:0.987869\n",
      "[246]\ttrain-mlogloss:0.987612\n",
      "[247]\ttrain-mlogloss:0.987167\n",
      "[248]\ttrain-mlogloss:0.986787\n",
      "[249]\ttrain-mlogloss:0.986379\n",
      "[250]\ttrain-mlogloss:0.985878\n"
     ]
    }
   ],
   "source": [
    "#XGBoost 모델 재학습\n",
    "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featur importance :\n",
      "('fecha_alta_month', 17543)\n",
      "('age', 16408)\n",
      "('renta', 14951)\n",
      "('fecha_alta_year', 12555)\n",
      "('age_prev', 12501)\n",
      "('nomprov', 11892)\n",
      "('antiguedad', 10775)\n",
      "('antiguedad_prev', 9556)\n",
      "('canal_entrada', 8979)\n",
      "('renta_prev', 8076)\n",
      "('fecha_alta_month_prev', 7846)\n",
      "('nomprov_prev', 7609)\n",
      "('canal_entrada_prev', 6222)\n",
      "('fecha_alta_year_prev', 6046)\n",
      "('sexo', 5000)\n",
      "('ind_recibo_ult1_prev', 4599)\n",
      "('ind_ecue_fin_ult1_prev', 4577)\n",
      "('ind_cco_fin_ult1_prev', 3974)\n",
      "('ind_cno_fin_ult1_prev', 3686)\n",
      "('segmento', 3548)\n",
      "('ind_reca_fin_ult1_prev', 3244)\n",
      "('segmento_prev', 3238)\n",
      "('ind_tjcr_fin_ult1_prev', 3150)\n",
      "('tiprel_1mes', 2301)\n",
      "('ind_valo_fin_ult1_prev', 2271)\n",
      "('sexo_prev', 2264)\n",
      "('ind_ctop_fin_ult1_prev', 2261)\n",
      "('ind_nom_pens_ult1_prev', 2259)\n",
      "('ind_dela_fin_ult1_prev', 2197)\n",
      "('ind_nomina_ult1_prev', 1909)\n",
      "('ind_ctpp_fin_ult1_prev', 1893)\n",
      "('tiprel_1mes_prev', 1696)\n",
      "('ind_actividad_cliente', 1690)\n",
      "('ind_fond_fin_ult1_prev', 1490)\n",
      "('ind_actividad_cliente_prev', 1324)\n",
      "('ind_nuevo', 1324)\n",
      "('ind_ctma_fin_ult1_prev', 1296)\n",
      "('indext', 1191)\n",
      "('ind_plan_fin_ult1_prev', 1074)\n",
      "('ind_hip_fin_ult1_prev', 798)\n",
      "('ind_nuevo_prev', 676)\n",
      "('indext_prev', 646)\n",
      "('indrel_1mes', 595)\n",
      "('ind_deco_fin_ult1_prev', 471)\n",
      "('indrel_1mes_prev', 378)\n",
      "('pais_residencia', 356)\n",
      "('ind_viv_fin_ult1_prev', 335)\n",
      "('ind_ctju_fin_ult1_prev', 316)\n",
      "('ind_empleado_prev', 312)\n",
      "('pais_residencia_prev', 272)\n",
      "('ind_empleado', 255)\n",
      "('indrel', 188)\n",
      "('ind_deme_fin_ult1_prev', 163)\n",
      "('ind_pres_fin_ult1_prev', 151)\n",
      "('ult_fec_cli_1t_month', 90)\n",
      "('ind_cder_fin_ult1_prev', 90)\n",
      "('ult_fec_cli_1t_year', 51)\n",
      "('indfall_prev', 44)\n",
      "('indresi_prev', 38)\n",
      "('indfall', 33)\n",
      "('indresi', 32)\n",
      "('conyuemp_prev', 31)\n",
      "('conyuemp', 15)\n",
      "('ult_fec_cli_1t_month_prev', 9)\n",
      "('tipodom_prev', 5)\n",
      "('indrel_prev', 2)\n"
     ]
    }
   ],
   "source": [
    "# 변수 중요도 출력\n",
    "print(\"Featur importance :\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key = lambda kv : kv[1], reverse=True):\n",
    "    print(kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측값\n",
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst = preds_tst - tst.as_matrix(columns = [prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file = open('./model/xgb.baseline.2015-06-28', 'w')\n",
    "submit_file.write('ncodpers, added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key = lambda a : a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "/home/jeongchanwoo/miniconda3/envs/ml_python_linux/lib/python3.5/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 캐글 제출을 위하여 테스트 데이터에 대한 예측 값을 구한다.\n",
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "# 제출 파일을 생성한다.\n",
    "submit_file = open('./model/xgb.baseline.2015-06-28',  'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.11019537e-05,  4.11019537e-05, -9.99864238e-01, ...,\n",
       "         2.90868618e-02,  2.85249986e-02,  7.49141097e-01],\n",
       "       [ 1.96851051e-05,  1.96850870e-05, -9.99978995e-01, ...,\n",
       "         3.87322418e-02,  3.88861187e-02,  8.19990754e-01],\n",
       "       [ 1.79388153e-05,  1.79388153e-05, -9.99965932e-01, ...,\n",
       "         4.29779887e-02,  4.26549390e-02,  8.62234235e-01],\n",
       "       ...,\n",
       "       [ 2.81367429e-05,  2.81367138e-05, -9.99923195e-01, ...,\n",
       "         1.60683934e-02,  2.50709709e-02,  5.20530820e-01],\n",
       "       [ 1.26324921e-05,  1.26324921e-05, -9.99975804e-01, ...,\n",
       "         5.76154841e-03,  1.02906991e-02,  8.68743300e-01],\n",
       "       [ 3.38822538e-05,  3.38822538e-05,  5.69434345e-01, ...,\n",
       "         6.00944273e-03,  1.17543945e-02,  1.32302165e-01]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
